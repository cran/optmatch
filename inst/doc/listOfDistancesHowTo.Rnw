%\VignetteIndexEntry{HowTo: lists of distance matrices for large matching problems}
%\VignetteDepends{boot, optmatch}
%\VignettePackage{optmatch}
\documentclass[12pt]{article}

\author{Ben Hansen}

\title{How to create lists of distance matrices for large matching problems}


\begin{document}
\maketitle

Optimal matching of treatment (case) to control subjects requires
a treatment-by-control ($n_t \times n_c$) matrix of
discrepancies, ratings of the desirability of each potential
match.  In propensity-score matching, for example, the
discrepancy matrix gives magnitudes of differences on the
propensity score for each possible pairing of a treatment to a
control.  Often the data arrive in a data frame containing a row
for each observation and a column for each of $k$ variables, in
which case the discrepancies are usually calculated from
information in this frame.  As observations are added, a distance
matrix derived from a data frame grows quite a bit more quickly
than the size of the frame, since the distance matrix contains
$n_t \times n_c$ entries whereas the data frame contains only
$(n_t + n_c) k$ entries.  As the number of observations moves into the
thousands, an $n_t \times n_c$ numeric matrix quickly exceeds the
storage capacity of most desktop computers, even as the $(n_t +
n_c)k$ data frame is readily accommodated.

For these situations, it becomes necessary to split the matching
problem, and with it the data frame, into parts.  A data set with 2000
treatment subjects and 4000 controls would seem to call for a $2000
\times 4000$ distance matrix, containing 8 million cells; but by
separately matching men to men and women to women, one might split it
into two matching problems, each requiring just 2 million cells.  The
total storage requirements would be halved; furthermore, it is easier
for R to store two matrices of 2 million cells each than it would be
for it to store a single 4 million cell matrix.  It is up to the data
analyst to decide which variable or variables to split along, but
once this decision is made, \texttt{fullmatch} has some features to
ease separation of the constituent matching problems and the joining
of their ultimate results.

For simplicity, assume that matching is to be done along a single
variable, such as a propensity score, and assume that the variable
appears in a data frame that also contains an indicator of
treatment/control group membership.  For concreteness, let these
variables be named \texttt{Pscore} and \texttt{TrtDummy}. (If the
variable is an estimated propensity score or other variable
synthesized from given data, then it may have to be added to the
original data frame in order to achieve this configuration.)  In this
case the discrepancy matrix is simply a matrix of absolute differences
between treatment and control propensity scores.  

\begin{verbatim}
myDist <- function(names,data) 
          {
          stopifnot(all(names %in% row.names(data)))
          trtnames <-
	  names[as.logical(data[names,'TrtDummy'])]
          ctlnames <-
          names[!data[names,'TrtDummy']]
          ans <-
	  outer(X=data[trtnames,'Pscore'],
                Y=data[ctlnames,'Pscore'],
                FUN=function(X,Y){abs(X-Y)}
                )
          dimnames(ans) <- list(trtnames,ctlnames)
          ans
          }
\end{verbatim}

\texttt{myDist} forms a distance matrix for only those treatments
and controls belonging to a specified subset of the data frame.
(The \texttt{outer} command is quite useful in this regard; it
tends to be much faster than, say, coding the same operations in
a \texttt{for} loop.)  It will be important for later uses that
the matrix produced by \texttt{myDist()} record names of the
treatment and control subjects as well as distances between them.
Since \texttt{myDist} forms a distance matrix only for those
names it is given in its first argument, it's easy to test it on
a small subset of your data frame.

To split a matching problem along lines of, say, gender and race, proceed
as follows.
\newpage

\begin{verbatim}
distlist <- tapply(row.names(myDataFrame), 
                   myDataFrame[,c('gender', 'race')],
                   myDist, 
                   data=myDataFrame)
fm1 <- fullmatch(distlist)
fm2 <- fullmatch(distlist, 
                 min.controls=
                           tapply(myDataFrame$TrtDummy,
                                  myDataFrame[,c('gender', 'race')],
                                  function(x){
                                    pmax(floor(sum(!x)/sum(x)),
                                         1/ceiling(sum(x)/sum(!x)))} )
                 )
\end{verbatim}


The method being described can be adapted to more complicated
discrepancies, such as Mahalanobis discrepancies, combinations of
Mahalanobis and propensity calipers, or variations on the Mahalanobis
distance such as those produced by Sekhon's Matching package; the
changes required to effect such an adaptation will be made to
\texttt{myDist()}.

The code above is illustrative.  Below is a small working
example, using the nuclear plants data set from Cox and Snell's
\emph{Applied Statistics} (1981, p.82).  It requires the ``boot''
package, which seems to be part of the base installation.
Excluding the six ``partial turnkey'' plants (\texttt{pt==1}), I
stratify on whether the plant was build in the northeast
(\texttt{ne}) or not, then match on the plant capacities
(\texttt{cap}) within a caliper on date of construction
(\texttt{date}).  Besides the commands to do this, displayed
below are the two distance matrices produced, one each for
\texttt{ne} equal to 0 and 1, and the matched sets that result
from full matching separately within the two strata.
\newpage

<<echo=TRUE>>=
library(optmatch)
library(boot)
data(nuclear)
myDataFrame <- nuclear[nuclear$pt==0,]
row.names(myDataFrame)[as.logical(myDataFrame$pr)] <- LETTERS[1:7]
row.names(myDataFrame)[!(myDataFrame$pr)] <- LETTERS[8:26]
myDist <- function(names,data) 
          {
          stopifnot(all(names %in% row.names(data)))
          trtnames <-
	  names[as.logical(data[names,'pr'])]
          ctlnames <-
          names[!data[names,'pr']]
          ans <-
	  outer(data[trtnames,'cap'],data[ctlnames,'cap'],
                FUN=function(X,Y){abs(X-Y)})
          ans <- ans/
	  outer(data[trtnames,'date'],data[ctlnames,'date'],
                FUN=function(X,Y){(abs(X-Y)<1.5)})
          dimnames(ans) <- list(trtnames,ctlnames)
          ans
          }
@

\newpage
\thispagestyle{empty}

\enlargethispage*{1000pt}
<<echo=TRUE>>=
(distlist <- tapply(row.names(myDataFrame), myDataFrame[,'ne'],
                   myDist, data=myDataFrame))
fm1 <- fullmatch(distlist)
split(names(fm1), fm1)
@

\end{document}
